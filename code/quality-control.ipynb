{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore quality control statistics for election audits\n",
    "\n",
    "\n",
    "Given reported results, and evidence from a random sample of ballots, does the sample plausibly come from the reported results?\n",
    "\n",
    "If not, might there be problems with the sample, the interpretations, or the original tabulation?\n",
    "\n",
    "Follow the approach of the LRT test statistic described at https://www.biostat.wisc.edu/~kbroman/teaching/labstat/fourth/notes02.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import percentileofscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from audit of Montgomery OH 2020 primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = \"\"\"\tCandidates\tResults\tRound 1\tTotal\tRequired\n",
    "0\tBennet\t51\t0\t0\t\n",
    "1\tBiden\t29011\t118\t118\t107\n",
    "2\tBloomberg\t702\t4\t4\t\n",
    "3\tButtigieg\t525\t2\t2\t\n",
    "4\tGabbard\t137\t0\t0\t\n",
    "5\tKlobuchar\t406\t1\t1\t\n",
    "6\tPatrick\t27\t0\t0\t\n",
    "7\tSanders\t5713\t20\t20\t\n",
    "8\tSteyer\t62\t0\t0\t\n",
    "9\tWarren\t1118\t4\t4\t\n",
    "10\tWrite_Ins\t122\t1\t1\t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = io.StringIO(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.read_csv(s, delimiter='\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Results</th>\n",
       "      <th>Round 1</th>\n",
       "      <th>Total</th>\n",
       "      <th>Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bennet</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Biden</td>\n",
       "      <td>29011</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>702</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Buttigieg</td>\n",
       "      <td>525</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gabbard</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Klobuchar</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>5713</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Steyer</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Warren</td>\n",
       "      <td>1118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Write_Ins</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Candidates  Results  Round 1  Total  Required\n",
       "0            0     Bennet       51        0      0       NaN\n",
       "1            1      Biden    29011      118    118     107.0\n",
       "2            2  Bloomberg      702        4      4       NaN\n",
       "3            3  Buttigieg      525        2      2       NaN\n",
       "4            4    Gabbard      137        0      0       NaN\n",
       "5            5  Klobuchar      406        1      1       NaN\n",
       "6            6    Patrick       27        0      0       NaN\n",
       "7            7    Sanders     5713       20     20       NaN\n",
       "8            8     Steyer       62        0      0       NaN\n",
       "9            9     Warren     1118        4      4       NaN\n",
       "10          10  Write_Ins      122        1      1       NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reported = rdf.Results.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reported_prob = reported / sum(reported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34657021e-03, 7.65987221e-01, 1.85351428e-02, 1.38617521e-02,\n",
       "       3.61725722e-03, 1.07197550e-02, 7.12890109e-04, 1.50842266e-01,\n",
       "       1.63700692e-03, 2.95189312e-02, 3.22120716e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reported_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [0, 118, 4, 2, 0, 1, 0, 20, 0, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = sum(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum-likelihood sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_sample = reported_prob * sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.01985531e-01, 1.14898083e+02, 2.78027143e+00, 2.07926282e+00,\n",
       "       5.42588583e-01, 1.60796325e+00, 1.06933516e-01, 2.26263400e+01,\n",
       "       2.45551038e-01, 4.42783968e+00, 4.83181074e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at differences between original sample and maximum-likelihood sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2, 3.1, 1.22, -0.08, -0.54, -0.61, -0.11, -2.63, -0.25, -0.43, 0.52]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(s-m, 2) for s,m in zip(sample, ml_sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a bunch of samples from the reported distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrt_stat(counts, expected_counts):\n",
    "    \"\"\"Likelihood ratio test statistic.\n",
    "    counts (list(number)):          observed counts\n",
    "    expected_counts (list(float)):  expected counts\n",
    "\n",
    "    Return a statistic measuring how likely is it that the observed counts \n",
    "    comes from the multinomial distribution exemplified by expected_counts.\n",
    "    The sum of counts and expected counts should be the same.\n",
    "\n",
    "    Cf. chi squared, but works for smaller numbers?\n",
    "    from https://www.biostat.wisc.edu/~kbroman/teaching/labstat/fourth/notes02.pdf\n",
    "\n",
    "    >>> lrt_stat([35, 43, 22], [25.0, 50.0, 25.0])\n",
    "    4.957619699875772\n",
    "    >>> lrt_stat([0, 43, 22], [25.0, 50.0, 25.0])\n",
    "    -18.59543686360913\n",
    "\n",
    "    TODO: is substituting 0.5 an ok way to handle 0 counts? Need to avoid domain error in log.\n",
    "    \"\"\"\n",
    "\n",
    "    return 2 * sum(ni * math.log(max(ni,0.5) / ni0) for ni, ni0 in zip(counts, expected_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrt_pres(data):\n",
    "    \"Run lrt_stat on data\"\n",
    "    return lrt_stat(data, ml_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate distribution of given test statistic via simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 100000\n",
    "# trials = 1000000 # 1M takes a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialset = np.random.multinomial(sample_size, reported_prob, size=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats_detail = [(round(lrt_stat(trial, reported_prob * sample_size), 3), trial) for trial in trialset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = sorted([v[0] for v in test_stats_detail])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick some extreme probabilities for the quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [0.0] + [10**n for n in range(-6, 0)] + [(1-10**n) for n in range(-1, -7, -1)] + [1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.quantile(test_stats, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 2.007),\n",
       " (1e-06, 2.011799952),\n",
       " (1e-05, 2.05499952),\n",
       " (0.0001, 2.173),\n",
       " (0.001, 2.603),\n",
       " (0.01, 3.368),\n",
       " (0.1, 5.03),\n",
       " (0.9, 14.624),\n",
       " (0.99, 20.947039999999976),\n",
       " (0.999, 25.948035000000136),\n",
       " (0.9999, 31.02901410000067),\n",
       " (0.99999, 39.92606884002331),\n",
       " (0.999999, 46.121606884012344),\n",
       " (1.0, 46.81)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(probs, quantiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Montgomery sample is rather close to the expected sample - closer than all but 2.3% of random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrt_sample = lrt_stat(sample, reported_prob * sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.308"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentileofscore(test_stats, lrt_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore what outliers would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorrect data entry of contest, with one extra candidate, shifting e.g. Sanders votes to \n",
    "typosample = [0, 118, 4, 2, 0, 2, 0, 0, 26, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 118, 4, 2, 0, 2, 0, 0, 26, 0, 4]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typosample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 118, 4, 2, 0, 1, 0, 20, 0, 4, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269.26535915406293"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrt_pres(typosample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(sample, count, index=0):\n",
    "    \"perturb the 'index' dimension of the sample by count and return the LRT stat, p-value and perturbed sample\"\n",
    "\n",
    "    dims = len(sample)\n",
    "    perturbed = np.array(sample)\n",
    "    perturbed[index] += count\n",
    "    lrt = lrt_pres(perturbed)\n",
    "    return (round(lrt, 3), round(100.0-percentileofscore(test_stats, lrt), 3), str(perturbed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more than 2 or 3 to the sample count for first candidate might raise a flag (p-value of 0.014 or 0.00064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4, (-3.453, 100.0, '[ -4 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (-3, (-1.641, 100.0, '[ -3 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (-2, (0.172, 100.0, '[ -2 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (-1, (1.985, 100.0, '[ -1 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (0, (3.798, 97.692, '[  0 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (1, (6.997, 70.936, '[  1 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (2, (12.969, 17.063, '[  2 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (3, (19.987, 1.432, '[  3 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (4, (27.685, 0.042, '[  4 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (5, (35.888, 0.004, '[  5 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (6, (44.494, 0.001, '[  6 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (7, (53.434, 0.0, '[  7 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (8, (62.662, 0.0, '[  8 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (9, (72.14, 0.0, '[  9 118   4   2   0   1   0  20   0   4   1]'))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, perturb(sample, i, 0)) for i in range(-4, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding even 6 votes to Biden's count doesn't look very unusual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4, (-4.278, 100.0, '[  0 114   4   2   0   1   0  20   0   4   1]')),\n",
       " (-3, (-2.285, 100.0, '[  0 115   4   2   0   1   0  20   0   4   1]')),\n",
       " (-2, (-0.275, 100.0, '[  0 116   4   2   0   1   0  20   0   4   1]')),\n",
       " (-1, (1.753, 100.0, '[  0 117   4   2   0   1   0  20   0   4   1]')),\n",
       " (0, (3.798, 97.692, '[  0 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (1, (5.86, 82.604, '[  0 119   4   2   0   1   0  20   0   4   1]')),\n",
       " (2, (7.938, 60.467, '[  0 120   4   2   0   1   0  20   0   4   1]')),\n",
       " (3, (10.033, 38.316, '[  0 121   4   2   0   1   0  20   0   4   1]')),\n",
       " (4, (12.145, 21.724, '[  0 122   4   2   0   1   0  20   0   4   1]')),\n",
       " (5, (14.273, 11.247, '[  0 123   4   2   0   1   0  20   0   4   1]')),\n",
       " (6, (16.418, 5.365, '[  0 124   4   2   0   1   0  20   0   4   1]')),\n",
       " (7, (18.578, 2.415, '[  0 125   4   2   0   1   0  20   0   4   1]')),\n",
       " (8, (20.755, 1.074, '[  0 126   4   2   0   1   0  20   0   4   1]')),\n",
       " (9, (22.947, 0.432, '[  0 127   4   2   0   1   0  20   0   4   1]')),\n",
       " (10, (25.155, 0.155, '[  0 128   4   2   0   1   0  20   0   4   1]')),\n",
       " (11, (27.379, 0.047, '[  0 129   4   2   0   1   0  20   0   4   1]')),\n",
       " (12, (29.618, 0.021, '[  0 130   4   2   0   1   0  20   0   4   1]')),\n",
       " (13, (31.873, 0.008, '[  0 131   4   2   0   1   0  20   0   4   1]')),\n",
       " (14, (34.143, 0.005, '[  0 132   4   2   0   1   0  20   0   4   1]'))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, perturb(sample, i, 1)) for i in range(-4, 15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanders' counts aren't much more sensitive than Biden's, with this test, in this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4, (-2.356, 100.0, '[  0 118   4   2   0   1   0  16   0   4   1]')),\n",
       " (-3, (-0.987, 100.0, '[  0 118   4   2   0   1   0  17   0   4   1]')),\n",
       " (-2, (0.498, 100.0, '[  0 118   4   2   0   1   0  18   0   4   1]')),\n",
       " (-1, (2.096, 99.998, '[  0 118   4   2   0   1   0  19   0   4   1]')),\n",
       " (0, (3.798, 97.692, '[  0 118   4   2   0   1   0  20   0   4   1]')),\n",
       " (1, (5.6, 85.061, '[  0 118   4   2   0   1   0  21   0   4   1]')),\n",
       " (2, (7.498, 65.417, '[  0 118   4   2   0   1   0  22   0   4   1]')),\n",
       " (3, (9.487, 43.744, '[  0 118   4   2   0   1   0  23   0   4   1]')),\n",
       " (4, (11.562, 25.617, '[  0 118   4   2   0   1   0  24   0   4   1]')),\n",
       " (5, (13.721, 13.477, '[  0 118   4   2   0   1   0  25   0   4   1]')),\n",
       " (6, (15.96, 6.294, '[  0 118   4   2   0   1   0  26   0   4   1]')),\n",
       " (7, (18.276, 2.726, '[  0 118   4   2   0   1   0  27   0   4   1]')),\n",
       " (8, (20.666, 1.111, '[  0 118   4   2   0   1   0  28   0   4   1]')),\n",
       " (9, (23.128, 0.401, '[  0 118   4   2   0   1   0  29   0   4   1]')),\n",
       " (10, (25.658, 0.114, '[  0 118   4   2   0   1   0  30   0   4   1]')),\n",
       " (11, (28.255, 0.033, '[  0 118   4   2   0   1   0  31   0   4   1]')),\n",
       " (12, (30.917, 0.013, '[  0 118   4   2   0   1   0  32   0   4   1]')),\n",
       " (13, (33.641, 0.005, '[  0 118   4   2   0   1   0  33   0   4   1]')),\n",
       " (14, (36.426, 0.004, '[  0 118   4   2   0   1   0  34   0   4   1]'))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, perturb(sample, i, 7)) for i in range(-4, 15)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "99px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
